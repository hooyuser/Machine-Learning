\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Terminology and Framework}{2}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}The Common Form of Optimal Decision Function }{3}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Loss function for quantitative output variables: squared error loss}{3}{subsection.1.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Loss function for categorical output variable: 0-1 indicator}{4}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Generalization Error Bound}{4}{section.1.3}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{1.3.{1}}{}}{4}{theorem.1.3.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Linear Model}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Finite Sample Linear Model}{5}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Statistic model setup}{5}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Ordinary least square estimate}{5}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}SVM}{7}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}linear SVM}{7}{section.3.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}KNN}{8}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Nearest-neighbor methods}{8}{section.4.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Decision Tree}{9}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Regression Trees}{9}{section.5.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Neural Networks}{11}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Single hidden layer back-propagation network}{11}{section.6.1}}
